import requests
from bs4 import BeautifulSoup
from typing import List, Dict
from src.domain.ports.scraper_port import NewsScraperPort

class BBCRssScraper(NewsScraperPort):
    def __init__(self):
        # BBC'nin Teknoloji haberleri RSS adresi
        self.url = "http://feeds.bbci.co.uk/news/technology/rss.xml"
        self.source_name = "BBC Technology"

    def fetch_news(self) -> List[Dict]:
        print(f"ğŸ“¡ {self.source_name} kaynaÄŸÄ±na baÄŸlanÄ±lÄ±yor...")
        news_list = []
        
        try:
            # 1. Ä°stek At (Request)
            # Timeout=10 sn ekliyoruz ki internet yoksa kod sonsuza kadar beklemesin
            response = requests.get(self.url, timeout=10)
            response.raise_for_status() # Hata varsa (Ã–rn: 404 Sayfa Yok) iÅŸlemi durdur
            
            # 2. Gelen XML Verisini ParÃ§ala (Parse)
            soup = BeautifulSoup(response.content, features="xml")
            items = soup.find_all("item")
            
            print(f"âœ… {len(items)} adet haber bulundu. Ä°lk 5 tanesi alÄ±nÄ±yor.")

            # 3. Veriyi Bizim FormatÄ±mÄ±za Ã‡evir (Mapping)
            # Sadece en gÃ¼ncel 5 haberi alÄ±yoruz
            for item in items[:5]:
                title = item.find("title").text if item.find("title") else "BaÅŸlÄ±ksÄ±z"
                description = item.find("description").text if item.find("description") else "Ä°Ã§erik yok"
                link = item.find("link").text if item.find("link") else ""
                
                news_list.append({
                    "title": title,
                    "content": description,
                    "source": self.source_name,
                    "url": link
                })
                
            return news_list
            
        except Exception as e:
            print(f"âŒ Hata oluÅŸtu: {e}")
            return []